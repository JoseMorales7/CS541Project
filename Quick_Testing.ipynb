{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3103318f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "import random\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e66e9bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "class CitiesData(Dataset):\n",
    "    def __init__(self, dataParentFolder: str, dataIdxs: list, transform = None, batch_size=128):\n",
    "        self.dataParentFolder = dataParentFolder\n",
    "        self.transform = transform\n",
    "\n",
    "        imagePaths = []\n",
    "        for city in os.listdir(dataParentFolder):\n",
    "            path = os.path.join(dataParentFolder, city)\n",
    "            imagePaths.extend([os.path.join(path, imageFile).replace(\"\\\\\", \"/\") for imageFile in os.listdir(path)])\n",
    "            \n",
    "        self.imagePaths = np.array(imagePaths)[dataIdxs]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imagePaths)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        imagePath = self.imagePaths[idx]\n",
    "\n",
    "        pathSplits = imagePath.split(self.dataParentFolder)[1].split(\"/\")\n",
    "        city = pathSplits[0]\n",
    "        city =self.city_to_vector(city)\n",
    "        longitude, latitude = pathSplits[1].split(\",\")\n",
    "        latitude = latitude.split(\".jpg\")[0]\n",
    "        image = io.imread(imagePath)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "    \n",
    "        return image, city, float(longitude), float(latitude)\n",
    "    \n",
    "    def city_to_vector(self, city):\n",
    "        output = np.zeros(10)\n",
    "        for i in range(len(city)):\n",
    "            if city == 'Atlanta':\n",
    "                output[0] = 1\n",
    "            elif city == 'Austin':\n",
    "                output[1] = 1\n",
    "            elif city == 'Boston':\n",
    "                output[2] = 1\n",
    "            elif city == 'Chicago':\n",
    "                output[3] = 1\n",
    "            elif city == 'LosAngeles':\n",
    "                output[4] = 1\n",
    "            elif city == 'Miami':\n",
    "                output[5] = 1\n",
    "            elif city == 'NewYork':\n",
    "                output[6] = 1\n",
    "            elif city == 'Phoenix':\n",
    "                output[7] = 1\n",
    "            elif city == 'SanFrancisco':\n",
    "                output[8] = 1\n",
    "            elif city == 'Seattle':\n",
    "                output[9] = 1\n",
    "        return torch.tensor(output)\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06cc2c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCitiesDataLoader(dataParentFolder: str, batchSize: int = 128, transforms = None):\n",
    "    cityIdxs = [0]\n",
    "    totalPoints = 0\n",
    "    for city in os.listdir(dataParentFolder):\n",
    "        totalPoints += len(os.listdir(os.path.join(dataParentFolder, city)))\n",
    "        cityIdxs.append(totalPoints)\n",
    "\n",
    "    trainIdxs = []\n",
    "    validIdxs = []\n",
    "    testIdxs = []\n",
    "    for i in range(len(cityIdxs) - 1):\n",
    "        start = cityIdxs[i]\n",
    "        stop = cityIdxs[i + 1]\n",
    "\n",
    "        num_train = int(np.round((stop - start) / 100 * 90))\n",
    "        num_valid = int(round(num_train * 0.025))\n",
    "\n",
    "        num_train -= num_valid\n",
    "        num_valid += num_train\n",
    "\n",
    "        # Shuffle all training stimulus images\n",
    "        idxs = np.arange(start, stop)\n",
    "\n",
    "        np.random.shuffle(idxs)\n",
    "\n",
    "        # Assign 90% of the shuffled stimulus images for each city to the training partition,\n",
    "        # and 10% to the test partition\n",
    "        trainIdxs.extend(idxs[:num_train])\n",
    "        validIdxs.extend(idxs[num_train:num_valid])\n",
    "        testIdxs.extend(idxs[num_valid:])\n",
    "\n",
    "    trainData = CitiesData(dataParentFolder, trainIdxs, transform=transforms)\n",
    "    validData = CitiesData(dataParentFolder, validIdxs, transform=transforms)\n",
    "    testData = CitiesData(dataParentFolder, testIdxs, transform=transforms)\n",
    "\n",
    "    trainDataLoader = DataLoader(trainData, batch_size=batchSize, shuffle=True)\n",
    "    validDataLoader = DataLoader(validData, batch_size=batchSize, shuffle=True)\n",
    "    testDataLoader = DataLoader(testData, batch_size=batchSize, shuffle=True)\n",
    "\n",
    "    return trainDataLoader, validDataLoader, testDataLoader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6b93537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBalancedCitiesDataLoader(dataParentFolder: str, augmentedParentFolder: str, batchSize: int = 128, transforms = None, balanced_size=200000):\n",
    "    # Generate a dataset of 10k images per class - 100k images total\n",
    "    class_balanced_size = int(balanced_size / 10)\n",
    "    start = time.time()\n",
    "    imagePaths = np.empty(balanced_size, dtype='object')\n",
    "    count = 0\n",
    "    for city in os.listdir(dataParentFolder):\n",
    "        path = os.path.join(dataParentFolder, city)\n",
    "        city_size = len(os.listdir(path))\n",
    "        if city_size >= class_balanced_size:\n",
    "            print(\"here\")\n",
    "            # Chop Data\n",
    "            path_list = os.listdir(path)\n",
    "            for i in range(class_balanced_size):\n",
    "                imageFile = path_list[i]\n",
    "                imagePaths[count] = os.path.join(path, imageFile).replace(\"\\\\\", \"/\")\n",
    "                count += 1\n",
    "            end = time.time()\n",
    "            print(end-start)\n",
    "            print(class_balanced_size)\n",
    "        else:\n",
    "            # First add original data\n",
    "            path_list = os.listdir(path)\n",
    "            for i in range(city_size):\n",
    "                imageFile = path_list[i]\n",
    "                imagePaths[count] = os.path.join(path, imageFile).replace(\"\\\\\", \"/\")\n",
    "                count += 1 \n",
    "\n",
    "            # Generate new data\n",
    "            augmented_path = os.path.join(augmentedParentFolder, city)\n",
    "            if len(os.listdir(augmented_path)) < class_balanced_size - city_size:\n",
    "                data_generator(dataParentFolder, augmentedParentFolder, city, class_balanced_size - city_size)\n",
    "\n",
    "            augmented_path_list = os.listdir(augmented_path)\n",
    "            for i in range(class_balanced_size - city_size):\n",
    "                imageFile = augmented_path_list[i]\n",
    "                imagePaths[count] = os.path.join(augmented_path, imageFile).replace(\"\\\\\", \"/\")\n",
    "                count += 1\n",
    "\n",
    "    trainIdxs = []\n",
    "    validIdxs = []\n",
    "    testIdxs = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        start = i * class_balanced_size\n",
    "        stop = (i+1) * class_balanced_size\n",
    "        \n",
    "        num_train = int(np.round((stop - start) / 100 * 90))\n",
    "        num_valid = int(round(num_train * 0.025))\n",
    "\n",
    "        num_train -= num_valid\n",
    "        num_valid += num_train\n",
    "\n",
    "        # Shuffle all training stimulus images\n",
    "        idxs = np.arange(start, stop)\n",
    "\n",
    "        np.random.shuffle(idxs)\n",
    "\n",
    "        # Assign 90% of the shuffled stimulus images for each city to the training partition,\n",
    "        # and 10% to the test partition\n",
    "        trainIdxs.extend(idxs[0:num_train])\n",
    "        validIdxs.extend(idxs[num_train:num_valid])\n",
    "        testIdxs.extend(idxs[num_valid:])\n",
    "\n",
    "    train_imagePaths = np.array(imagePaths)[trainIdxs]\n",
    "    valid_imagePaths = np.array(imagePaths)[validIdxs]\n",
    "    test_imagePaths = np.array(imagePaths)[testIdxs]\n",
    "\n",
    "    trainData = AugmentedCitiesData(dataParentFolder, augmentedParentFolder, train_imagePaths, transform=transforms)\n",
    "    validData = AugmentedCitiesData(dataParentFolder, augmentedParentFolder, valid_imagePaths, transform=transforms)\n",
    "    testData = AugmentedCitiesData(dataParentFolder, augmentedParentFolder, test_imagePaths, transform=transforms)\n",
    "\n",
    "    trainDataLoader = DataLoader(trainData, batch_size=batchSize, shuffle=True)\n",
    "    validDataLoader = DataLoader(validData, batch_size=batchSize, shuffle=True)\n",
    "    testDataLoader = DataLoader(testData, batch_size=batchSize, shuffle=True)\n",
    "\n",
    "    return trainDataLoader, validDataLoader, testDataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7d1446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugmentedCitiesData(Dataset):\n",
    "    def __init__(self, dataParentFolder: str, augmentedParentFolder: str, imagePaths, transform = None, batch_size=128):\n",
    "        self.dataParentFolder = dataParentFolder\n",
    "        self.augmentedParentFolder = augmentedParentFolder\n",
    "        self.transform = transform\n",
    "        self.imagePaths = imagePaths\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imagePaths)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        imagePath = self.imagePaths[idx]\n",
    "\n",
    "        pathSplits = imagePath.split(self.dataParentFolder)[1].split(\"/\")\n",
    "        city = pathSplits[0]\n",
    "        city =self.city_to_vector(city)\n",
    "        longitude, latitude = pathSplits[1].split(\",\")\n",
    "        latitude = latitude.split(\".jpg\")[0]\n",
    "        image = io.imread(imagePath)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, city, float(longitude), float(latitude)\n",
    "    \n",
    "    def city_to_vector(self, city):\n",
    "        output = np.zeros(10)\n",
    "        for i in range(len(city)):\n",
    "            if city == 'Atlanta':\n",
    "                output[0] = 1\n",
    "            elif city == 'Austin':\n",
    "                output[1] = 1\n",
    "            elif city == 'Boston':\n",
    "                output[2] = 1\n",
    "            elif city == 'Chicago':\n",
    "                output[3] = 1\n",
    "            elif city == 'LosAngeles':\n",
    "                output[4] = 1\n",
    "            elif city == 'Miami':\n",
    "                output[5] = 1\n",
    "            elif city == 'NewYork':\n",
    "                output[6] = 1\n",
    "            elif city == 'Phoenix':\n",
    "                output[7] = 1\n",
    "            elif city == 'SanFrancisco':\n",
    "                output[8] = 1\n",
    "            elif city == 'Seattle':\n",
    "                output[9] = 1\n",
    "        return torch.tensor(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "11db8420",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(original_data_folder, augmented_data_folder, city, amount):\n",
    "    \n",
    "    path = os.path.join(original_data_folder, city)\n",
    "    count = 0\n",
    "    while count < amount:\n",
    "        for imageFile in os.listdir(path):\n",
    "            imagePath = os.path.join(path, imageFile).replace(\"\\\\\", \"/\")\n",
    "\n",
    "            # Transform image - slight rotations and \n",
    "            image = Image.open(imagePath)\n",
    "\n",
    "            rand = random.randint(0,9)\n",
    "            if rand <= 2:\n",
    "                rand2= random.randint(-3,3)\n",
    "                image = image.rotate(rand2)\n",
    "            elif rand <= 5:\n",
    "                image = ImageOps.grayscale(image)\n",
    "            else:\n",
    "                image = image.filter(ImageFilter.GaussianBlur(1))\n",
    "\n",
    "\n",
    "            #Write Image to AugmentedData\n",
    "            image.save(os.path.join(os.path.join(augmented_data_folder, city), str(count) + \".0,1.0.jpg\").replace(\"\\\\\", \"/\"))\n",
    "\n",
    "            count += 1\n",
    "            if count >= amount:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "092bf84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_generator(\"./Data/\", \"./AugmentedData/\", \"Atlanta\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3b5ca7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "0.1760692596435547\n",
      "20000\n",
      "here\n",
      "0.341477632522583\n",
      "20000\n",
      "here\n",
      "0.4948923587799072\n",
      "20000\n",
      "here\n",
      "0.667870283126831\n",
      "20000\n",
      "here\n",
      "0.82342529296875\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "from torchvision.transforms import transforms\n",
    "batch_size = 32\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.RandomResizedCrop(size=(224, 224), antialias=True), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainDataLoader, validDataLoader, testDataLoader = getBalancedCitiesDataLoader(\"./Data/\", \"./AugmentedData/\", transforms = transform, batchSize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ebf2f157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175500\n",
      "4500\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "print(len(trainDataLoader))\n",
    "print(len(validDataLoader))\n",
    "print(len(testDataLoader))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "8907f5995ab74a6cd5df9da2d2bcd12f57f5b23c9c38358337eeb837f01ad676"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
